# Minimal example configuration for miniagent

llm:
  # Provider:
  #   - anthropic (default)
  #   - openai
  #   - minimaxi (MiniMax native; recommended)
  #   - openai-compatible (requires base_url)
  #   - google / gemini
  provider: minimaxi

  # API key for the selected provider
  api_key: YOUR_API_KEY_HERE

  # Model for the provider (examples):
  #   - anthropic: claude-sonnet-4-5-20250929
  #   - openai: gpt-4o-mini
  #   - minimaxi: MiniMax-M2
  #   - google/gemini: gemini-2.5-pro, gemini-2.5-flash
  model: MiniMax-M2

  # Optional: custom endpoint (mostly for openai-compatible)
  # base_url: https://api.example.com/v1

  retry:
    enabled: true
    max_retries: 3
    initial_delay: 1.0
    max_delay: 60.0
    exponential_base: 2.0

agent:
  max_steps: 50
  workspace_dir: ./workspace
  system_prompt_path: system_prompt.md
  # token_limit uses default 80000 if omitted
  completion_reserve: 2048

tools:
  enable_file_tools: true
  enable_bash: true
  # On Windows, the shell tool prefers PowerShell (pwsh), then Windows PowerShell,
  # and falls back to cmd.exe. On Unix, it uses `bash -lc`.
  enable_note: true
  enable_skills: true
  # Directory containing Claude Skills (SKILL.md files)
  # - By default, the entire `skills/` directory is embedded into the binary.
  # - At runtime, miniagent searches in this order and uses the first that exists:
  #     1) <this relative or absolute path>
  #     2) ./miniagent/<skills_dir>
  #     3) ./skills
  #     4) ~/.miniagent/skills (fallback location)
  # - If none exists on disk, the embedded skills are extracted to ~/.miniagent/skills.
  skills_dir: ./skills
  enable_mcp: true
  mcp_config_path: mcp.json
